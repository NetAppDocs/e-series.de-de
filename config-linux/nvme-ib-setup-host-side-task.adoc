---
permalink: config-linux/nvme-ib-setup-host-side-task.html 
sidebar: sidebar 
keywords: configure Linux host, express linux configuration, linux host, 
summary: Die Konfiguration eines NVMe-Initiators in einer InfiniBand-Umgebung umfasst die Installation und Konfiguration der infiniband-, nvme-cli- und rdma-Pakete, die Konfiguration von Initiator-IP-Adressen und das Einrichten der NVMe-of-Ebene auf dem Host. 
---
= Richten Sie NVMe over InfiniBand auf der Host-Seite ein
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
Die Konfiguration eines NVMe-Initiators in einer InfiniBand-Umgebung umfasst die Installation und Konfiguration der infiniband-, nvme-cli- und rdma-Pakete, die Konfiguration von Initiator-IP-Adressen und das Einrichten der NVMe-of-Ebene auf dem Host.

.Was Sie benötigen
Sie müssen das neueste kompatible Betriebssystem RHEL 7, RHEL 8, RHEL 9, SUSE Linux Enterprise Server 12 oder 15 Service Pack ausführen. Siehe https://mysupport.netapp.com/matrix["NetApp Interoperabilitäts-Matrix-Tool"^] Für eine vollständige Liste der aktuellen Anforderungen.

.Schritte
. installation der rdma-, nvme-cli- und infiniband-Pakete:
+
*SLES 12 oder SLES 15*

+
[listing]
----

# zypper install infiniband-diags
# zypper install rdma-core
# zypper install nvme-cli
----
+
*RHEL 7, RHEL 8 ODER RHEL 9*

+
[listing]
----

# yum install infiniband-diags
# yum install rdma-core
# yum install nvme-cli
----
. Installieren Sie für RHEL 8 oder RHEL 9 Netzwerkskripte:
+
*RHEL 8*

+
[listing]
----
# yum install network-scripts
----
+
*RHEL 9*

+
[listing]
----
# yum install NetworkManager-initscripts-updown
----
. Aktivieren Sie für RHEL 7 `ipoib`. Bearbeiten Sie die Datei /etc/rdma/rdma.conf und ändern Sie den Eintrag zum Laden `ipoib`:
+
[listing]
----
IPOIB_LOAD=yes
----
. Holen Sie den Host-NQN ab, mit dem der Host für ein Array konfiguriert werden kann.
+
[listing]
----
# cat /etc/nvme/hostnqn
----
. Überprüfen Sie, ob die IB-Port-Links aktiviert sind und der Status = aktiv:
+
[listing]
----
# ibstat
----
+
[listing]
----
CA 'mlx4_0'
        CA type: MT4099
        Number of ports: 2
        Firmware version: 2.40.7000
        Hardware version: 1
        Node GUID: 0x0002c90300317850
        System image GUID: 0x0002c90300317853
        Port 1:
                State: Active
                Physical state: LinkUp
                Rate: 40
                Base lid: 4
                LMC: 0
                SM lid: 4
                Capability mask: 0x0259486a
                Port GUID: 0x0002c90300317851
                Link layer: InfiniBand
        Port 2:
                State: Active
                Physical state: LinkUp
                Rate: 56
                Base lid: 5
                LMC: 0
                SM lid: 4
                Capability mask: 0x0259486a
                Port GUID: 0x0002c90300317852
                Link layer: InfiniBand
----
. Richten Sie IPv4-IP-Adressen an den ib-Ports ein.
+
*SLES 12 oder SLES 15*

+
Erstellen Sie die Datei /etc/sysconfig/Network/ifcfg-ib0 mit folgendem Inhalt.

+
[listing]
----

BOOTPROTO='static'
BROADCAST=
ETHTOOL_OPTIONS=
IPADDR='10.10.10.100/24'
IPOIB_MODE='connected'
MTU='65520'
NAME=
NETWORK=
REMOTE_IPADDR=
STARTMODE='auto'
----
+
Erstellen Sie dann die Datei /etc/sysconfig/Network/ifcfg-ib1:

+
[listing]
----

BOOTPROTO='static'
BROADCAST=
ETHTOOL_OPTIONS=
IPADDR='11.11.11.100/24'
IPOIB_MODE='connected'
MTU='65520'
NAME=
NETWORK=
REMOTE_IPADDR=
STARTMODE='auto'
----
+
*RHEL 7 oder RHEL 8*

+
Erstellen Sie die Datei /etc/sysconfig/Network-scripts/ifcfg-ib0 mit folgendem Inhalt.

+
[listing]
----

CONNECTED_MODE=no
TYPE=InfiniBand
PROXY_METHOD=none
BROWSER_ONLY=no
BOOTPROTO=static
IPADDR='10.10.10.100/24'
DEFROUTE=no
IPV4=FAILURE_FATAL=yes
IPV6INIT=no
NAME=ib0
ONBOOT=yes
----
+
Erstellen Sie dann die Datei /etc/sysconfig/Network-scripts/ifcfg-ib1:

+
[listing]
----

CONNECTED_MODE=no
TYPE=InfiniBand
PROXY_METHOD=none
BROWSER_ONLY=no
BOOTPROTO=static
IPADDR='11.11.11.100/24'
DEFROUTE=no
IPV4=FAILURE_FATAL=yes
IPV6INIT=no
NAME=ib1
ONBOOT=yes
----
+
*RHEL 9*

+
Verwenden Sie die `nmtui` Werkzeug zum Aktivieren und Bearbeiten einer Verbindung. Unten sehen Sie eine Beispieldatei `/etc/NetworkManager/system-connections/ib0.nmconnection` Das Tool generiert Folgendes:

+
[listing]
----
[connection]
id=ib0
uuid=<unique uuid>
type=infiniband
interface-name=ib0

[infiniband]
mtu=4200

[ipv4]
address1=10.10.10.100/24
method=manual

[ipv6]
addr-gen-mode=default
method=auto

[proxy]
----
+
Unten sehen Sie eine Beispieldatei `/etc/NetworkManager/system-connections/ib1.nmconnection` Das Tool generiert Folgendes:

+
[listing]
----
[connection]
id=ib1
uuid=<unique uuid>
type=infiniband
interface-name=ib1

[infiniband]
mtu=4200

[ipv4]
address1=11.11.11.100/24'
method=manual

[ipv6]
addr-gen-mode=default
method=auto

[proxy]
----
. Aktivieren Sie die `ib` Schnittstelle:
+
[listing]
----

# ifup ib0
# ifup ib1
----
. Überprüfen Sie die IP-Adressen, die Sie für die Verbindung mit dem Array verwenden werden. Führen Sie diesen Befehl für beide aus `ib0` Und `ib1`:
+
[listing]
----

# ip addr show ib0
# ip addr show ib1
----
+
Wie im Beispiel unten gezeigt, die IP-Adresse für `ib0` Ist `10.10.10.255`.

+
[listing]
----
10: ib0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 65520 qdisc pfifo_fast state UP group default qlen 256
    link/infiniband 80:00:02:08:fe:80:00:00:00:00:00:00:00:02:c9:03:00:31:78:51 brd 00:ff:ff:ff:ff:12:40:1b:ff:ff:00:00:00:00:00:00:ff:ff:ff:ff
    inet 10.10.10.255 brd 10.10.10.255 scope global ib0
       valid_lft forever preferred_lft forever
    inet6 fe80::202:c903:31:7851/64 scope link
       valid_lft forever preferred_lft forever
----
+
Wie im Beispiel unten gezeigt, die IP-Adresse für `ib1` Ist `11.11.11.255`.

+
[listing]
----
10: ib1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 65520 qdisc pfifo_fast state UP group default qlen 256
    link/infiniband 80:00:02:08:fe:80:00:00:00:00:00:00:00:02:c9:03:00:31:78:51 brd 00:ff:ff:ff:ff:12:40:1b:ff:ff:00:00:00:00:00:00:ff:ff:ff:ff
    inet 11.11.11.255 brd 11.11.11.255 scope global ib0
       valid_lft forever preferred_lft forever
    inet6 fe80::202:c903:31:7851/64 scope link
       valid_lft forever preferred_lft forever
----
. Legen Sie auf dem Host den NVMe-of-Layer fest. Erstellen Sie die folgenden Dateien unter /etc/modules-load.d/, um die zu laden `nvme-rdma` Kernel-Modul und stellen Sie sicher, dass das Kernel-Modul immer eingeschaltet ist, auch nach einem Neustart:
+
[listing]
----

# cat /etc/modules-load.d/nvme-rdma.conf
  nvme-rdma
----
+
Um die zu überprüfen `nvme-rdma` Kernel-Modul ist geladen, führen Sie diesen Befehl aus:

+
[listing]
----

# lsmod | grep nvme
nvme_rdma              36864  0
nvme_fabrics           24576  1 nvme_rdma
nvme_core             114688  5 nvme_rdma,nvme_fabrics
rdma_cm               114688  7 rpcrdma,ib_srpt,ib_srp,nvme_rdma,ib_iser,ib_isert,rdma_ucm
ib_core               393216  15 rdma_cm,ib_ipoib,rpcrdma,ib_srpt,ib_srp,nvme_rdma,iw_cm,ib_iser,ib_umad,ib_isert,rdma_ucm,ib_uverbs,mlx5_ib,qedr,ib_cm
t10_pi                 16384  2 sd_mod,nvme_core
----

